{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"CKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp sg   al   su     rbc        pc         pcc  \\\n",
       "0     2.000000  76.459948  c  3.0  0.0  normal  abnormal  notpresent   \n",
       "1     3.000000  76.459948  c  2.0  0.0  normal    normal  notpresent   \n",
       "2     4.000000  76.459948  a  1.0  0.0  normal    normal  notpresent   \n",
       "3     5.000000  76.459948  d  1.0  0.0  normal    normal  notpresent   \n",
       "4     5.000000  50.000000  c  0.0  0.0  normal    normal  notpresent   \n",
       "..         ...        ... ..  ...  ...     ...       ...         ...   \n",
       "394  51.492308  70.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "395  51.492308  70.000000  c  0.0  2.0  normal    normal  notpresent   \n",
       "396  51.492308  70.000000  c  3.0  0.0  normal    normal  notpresent   \n",
       "397  51.492308  90.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "398  51.492308  80.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba         bgr  ...        pcv            wc        rc  htn   dm  \\\n",
       "0    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "1    notpresent  148.112676  ...  34.000000  12300.000000  4.705597   no   no   \n",
       "2    notpresent   99.000000  ...  34.000000   8408.191126  4.705597   no   no   \n",
       "3    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "4    notpresent  148.112676  ...  36.000000  12400.000000  4.705597   no   no   \n",
       "..          ...         ...  ...        ...           ...       ...  ...  ...   \n",
       "394  notpresent  219.000000  ...  37.000000   9800.000000  4.400000   no   no   \n",
       "395  notpresent  220.000000  ...  27.000000   8408.191126  4.705597  yes  yes   \n",
       "396  notpresent  110.000000  ...  26.000000   9200.000000  3.400000  yes  yes   \n",
       "397  notpresent  207.000000  ...  38.868902   8408.191126  4.705597  yes  yes   \n",
       "398  notpresent  100.000000  ...  53.000000   8500.000000  4.900000   no   no   \n",
       "\n",
       "     cad  appet    pe  ane classification  \n",
       "0     no    yes   yes   no            yes  \n",
       "1     no    yes  poor   no            yes  \n",
       "2     no    yes  poor   no            yes  \n",
       "3     no    yes  poor  yes            yes  \n",
       "4     no    yes  poor   no            yes  \n",
       "..   ...    ...   ...  ...            ...  \n",
       "394   no    yes  poor   no            yes  \n",
       "395   no    yes  poor  yes            yes  \n",
       "396   no   poor  poor   no            yes  \n",
       "397   no    yes  poor  yes            yes  \n",
       "398   no    yes  poor   no             no  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...          0            0           0   \n",
       "1    137.528754  4.627244  10.700000  ...          1            0           0   \n",
       "2    138.000000  4.400000  12.000000  ...          1            0           0   \n",
       "3    138.000000  3.200000   8.100000  ...          1            0           0   \n",
       "4    137.528754  4.627244  11.800000  ...          1            0           0   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...          1            0           0   \n",
       "395  137.528754  4.627244   8.700000  ...          1            0           0   \n",
       "396  134.000000  2.700000   9.100000  ...          1            0           0   \n",
       "397  142.000000  5.500000   8.500000  ...          1            0           0   \n",
       "398  140.000000  5.000000  16.300000  ...          1            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0          0       0        0          1       1        0                   1  \n",
       "1          0       0        0          1       0        0                   1  \n",
       "2          0       0        0          1       0        0                   1  \n",
       "3          0       0        0          1       0        1                   1  \n",
       "4          0       0        0          1       0        0                   1  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394        0       0        0          1       0        0                   1  \n",
       "395        1       1        0          1       0        1                   1  \n",
       "396        1       1        0          0       0        0                   1  \n",
       "397        1       1        0          1       0        1                   1  \n",
       "398        0       0        0          1       0        0                   0  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "0    150\n",
       "Name: classification_yes, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"classification_yes\"].value_counts()\n",
    "#refer how many class classified\n",
    "#to find balanced or imbalanced\n",
    "#unique entry &counts---->(0-143,1-143)->balanced\n",
    "#(0-257,1-143)->imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
       "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep=dataset[['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
    "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
    "       'appet_yes', 'pe_yes', 'ane_yes', ]]\n",
    "dep=dataset[\"classification_yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep.shape#400-length ,3-i/p column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "394    1\n",
       "395    1\n",
       "396    1\n",
       "397    1\n",
       "398    0\n",
       "Name: classification_yes, Length: 399, dtype: uint8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training & test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(indep,dep,test_size=0.30,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ...............var_smoothing=1e-09;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-09;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-09;, score=0.964 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-09;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-09;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-08;, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-08;, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-08;, score=0.965 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-08;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-08;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-07;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-07;, score=0.930 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-07;, score=0.842 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-07;, score=0.895 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-07;, score=0.928 total time=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        45\n",
      "           1       1.00      0.97      0.99        75\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.99      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "[[45  0]\n",
      " [ 2 73]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]  # Varying the var_smoothing parameter\n",
    "}\n",
    "\n",
    "grid=GridSearchCV(GaussianNB(),param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)\n",
    "y_pred=grid.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(clf_report)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END .........................alpha=0.1;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=0.1;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=0.1;, score=0.895 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.1;, score=0.895 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=0.1;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=0.5;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=0.5;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=0.5;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.5;, score=0.859 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=0.5;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=1.0;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=1.0;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=1.0;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=1.0;, score=0.859 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=1.0;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=1.5;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=1.5;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=1.5;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=1.5;, score=0.842 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=1.5;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=2.0;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END .........................alpha=2.0;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END .........................alpha=2.0;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=2.0;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END .........................alpha=2.0;, score=0.857 total time=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81        45\n",
      "           1       0.98      0.73      0.84        75\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.83      0.86      0.82       120\n",
      "weighted avg       0.87      0.82      0.83       120\n",
      "\n",
      "[[44  1]\n",
      " [20 55]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0],  # Varying the alpha parameter\n",
    "    # Other parameters for MultinomialNB can be added to the param_grid\n",
    "    # For example, 'fit_prior': [True, False]\n",
    "}\n",
    "grid=GridSearchCV(MultinomialNB(),param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)\n",
    "y_pred=grid.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(clf_report)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ..........alpha=0.1, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.1, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.1, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.1, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.1, binarize=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.1, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.1, binarize=0.0;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.1, binarize=0.0;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.1, binarize=0.0;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.1, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.1, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.1, binarize=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.1, binarize=0.1;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.1, binarize=0.1;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.1, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.1, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.1, binarize=0.5;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.1, binarize=0.5;, score=0.947 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.1, binarize=0.5;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.1, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.1, binarize=1.0;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.1, binarize=1.0;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.1, binarize=1.0;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.1, binarize=1.0;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.1, binarize=1.0;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=0.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=0.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=0.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=0.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=0.5, binarize=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.5, binarize=0.0;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.5, binarize=0.0;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.5, binarize=0.0;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.5, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.5, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.5, binarize=0.1;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.5, binarize=0.1;, score=0.965 total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5] END ...........alpha=0.5, binarize=0.1;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.5, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.5, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.5, binarize=0.5;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.5, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.5, binarize=0.5;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.5, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.5, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=0.5, binarize=1.0;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=0.5, binarize=1.0;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=0.5, binarize=1.0;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=0.5, binarize=1.0;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=0.5, binarize=1.0;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=1.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=1.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=1.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=1.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=1.0, binarize=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.0, binarize=0.0;, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.0, binarize=0.0;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.0, binarize=0.0;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.0, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.0, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.0, binarize=0.1;, score=0.930 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.0, binarize=0.1;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.0, binarize=0.1;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.0, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.0, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.0, binarize=0.5;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.0, binarize=0.5;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.0, binarize=0.5;, score=0.912 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.0, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.0, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.0, binarize=1.0;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.0, binarize=1.0;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.0, binarize=1.0;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.0, binarize=1.0;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.0, binarize=1.0;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=1.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=1.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=1.5, binarize=None;, score=0.205 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..........alpha=1.5, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=1.5, binarize=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.5, binarize=0.0;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.5, binarize=0.0;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.5, binarize=0.0;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.5, binarize=0.0;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.5, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.5, binarize=0.1;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.5, binarize=0.1;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.5, binarize=0.1;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.5, binarize=0.1;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.5, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.5, binarize=0.5;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.5, binarize=0.5;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.5, binarize=0.5;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.5, binarize=0.5;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.5, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=1.5, binarize=1.0;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=1.5, binarize=1.0;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=1.5, binarize=1.0;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=1.5, binarize=1.0;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=1.5, binarize=1.0;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ..........alpha=2.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 2/5] END ..........alpha=2.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 3/5] END ..........alpha=2.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 4/5] END ..........alpha=2.0, binarize=None;, score=0.205 total time=   0.0s\n",
      "[CV 5/5] END ..........alpha=2.0, binarize=None;, score=0.211 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=2.0, binarize=0.0;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=2.0, binarize=0.0;, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=2.0, binarize=0.0;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=2.0, binarize=0.0;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=2.0, binarize=0.0;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=2.0, binarize=0.1;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=2.0, binarize=0.1;, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=2.0, binarize=0.1;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=2.0, binarize=0.1;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=2.0, binarize=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=2.0, binarize=0.5;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=2.0, binarize=0.5;, score=0.965 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=2.0, binarize=0.5;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=2.0, binarize=0.5;, score=0.965 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=2.0, binarize=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 1/5] END ...........alpha=2.0, binarize=1.0;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...........alpha=2.0, binarize=1.0;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END ...........alpha=2.0, binarize=1.0;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ...........alpha=2.0, binarize=1.0;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...........alpha=2.0, binarize=1.0;, score=0.848 total time=   0.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        45\n",
      "           1       1.00      0.96      0.98        75\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.97      0.98      0.97       120\n",
      "weighted avg       0.98      0.97      0.98       120\n",
      "\n",
      "[[45  0]\n",
      " [ 3 72]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:1183: RuntimeWarning: invalid value encountered in log\n",
      "  neg_prob = np.log(1 - np.exp(self.feature_log_prob_))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5, 2.0],  # Varying the alpha parameter\n",
    "    'binarize': [None, 0.0, 0.1, 0.5, 1.0]  # Varying the binarization threshold\n",
    "    # Other parameters for BernoulliNB can be added to the param_grid\n",
    "    # For example, 'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid=GridSearchCV(BernoulliNB(),param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)\n",
    "y_pred=grid.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(clf_report)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 83 is out of bounds for axis 1 with size 83\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 391 is out of bounds for axis 1 with size 310\n",
      "\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END .........................alpha=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........................alpha=0.1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........................alpha=0.1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.1;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=0.1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........................alpha=0.5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........................alpha=0.5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=0.5;, score=0.982 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=0.5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .........................alpha=1.0;, score=0.982 total time=   0.0s\n",
      "[CV 2/5] END ...........................alpha=1.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...........................alpha=1.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .........................alpha=1.0;, score=0.964 total time=   0.0s\n",
      "[CV 5/5] END ...........................alpha=1.0;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 21600 is out of bounds for axis 1 with size 19101\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 83 is out of bounds for axis 1 with size 83\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 391 is out of bounds for axis 1 with size 310\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 21600 is out of bounds for axis 1 with size 19101\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 83 is out of bounds for axis 1 with size 83\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 391 is out of bounds for axis 1 with size 310\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 221, in __call__\n",
      "    sample_weight=sample_weight,\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 83, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 1461, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 21600 is out of bounds for axis 1 with size 19101\n",
      "\n",
      "  UserWarning,\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 90 is out of bounds for axis 1 with size 84",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b415bae9780d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCategoricalNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict_proba\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1459\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m             \u001b[0mjll\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 90 is out of bounds for axis 1 with size 84"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "param_grid ={'alpha': [0.1, 0.5, 1.0]}\n",
    "grid=GridSearchCV(CategoricalNB(),param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)\n",
    "y_pred=grid.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(clf_report)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3906a327c756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mComplementNB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[1;34m\"Cannot clone object. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[1;33m+\u001b[0m \u001b[1;34m\"You should provide an instance of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[1;33m+\u001b[0m \u001b[1;34m\"scikit-learn estimator instead of a class.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                 )\n\u001b[0;32m     75\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "param_grid = {\n",
    "    'ngram_range': [(1, 1), (1, 2)],  # Adjust ngram range if needed\n",
    "    'alpha': [0.1, 0.5, 1.0]  # Alpha parameter values for ComplementNB\n",
    "}\n",
    "grid=GridSearchCV(ComplementNB,param_grid,refit=True,verbose=3,n_jobs=1,scoring='f1_weighted')\n",
    "grid.fit(x_train,y_train)\n",
    "y_pred=grid.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(clf_report)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e3a16b052848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(grid.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Making predictions on the test data using the best estimator found by GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "#print best parameter after tuning\n",
    "#print(grid.best_params_)\n",
    "\n",
    "re = grid.cv_results_\n",
    "\n",
    "# Making predictions on the test data using the best estimator found by GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ce4646e3554a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_predictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \"\"\"\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "\n",
    "grid_predictions=grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,grid_predictions,average='weighted')\n",
    "print(\"f1_macro value for best parameter{}:\".format(grid.best_params_),f1_macro)#optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79,0 correct diagonal,41,0 wrong diagonal\n",
    "#type1 error should low\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_report=classification_report(y_test,grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#overall performance(accuracy)=0.89\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,grid.predict_proba(x_test)[:,1])#receiver operating chareteristics area under curve(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame.from_dict(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age=int(input(\"Age:\"))\n",
    "bp=int(input(\"bp:\"))\n",
    "al=int(input(\"al:\"))\n",
    "su=int(input(\"su:\"))\n",
    "bgr=int(input(\"bgr:\"))\n",
    "bu=int(input(\"bu:\"))\n",
    "sc=int(input(\"sc:\"))\n",
    "sod=int(input(\"sod:\"))\n",
    "pot=int(input(\"pot:\"))\n",
    "hrmo=int(input(\"hrmo:\"))\n",
    "pcv=int(input(\"pcv:\"))\n",
    "wc=int(input(\"wc:\"))\n",
    "rc=int(input(\"rc:\"))\n",
    "sg_b=int(input(\"sg_b:\"))\n",
    "sg_c=int(input(\"sg_c:\"))\n",
    "sg_d=int(input(\"sg_d:\"))\n",
    "sg_e=int(input(\"sg_e:\"))\n",
    "rbc_normal=int(input(\"rbc_normal:\"))\n",
    "pc_normal=int(input(\"pc_normal:\"))\n",
    "pcc_present=int(input(\"pcc_present:\"))\n",
    "ba_present=int(input(\"ba_present:\"))\n",
    "htn_yes=int(input(\"htn_yes:\"))\n",
    "dm_yes=int(input(\"dm_yes:\"))\n",
    "cad_yes=int(input(\"cad_yes:\"))\n",
    "appet_yes=int(input(\"appet_yes:\"))\n",
    "pe_yes=int(input(\"pe_yes:\"))\n",
    "ane_yes=int(input(\"ane_yes:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Future_Prediction=grid.predict([[age, bp, al, su, bgr, bu, sc, sod, pot, hrmo,pcv,\n",
    "       wc, rc, sg_b, sg_c, sg_d, sg_e, rbc_normal, pc_normal,\n",
    "    pcc_present, ba_present, htn_yes, dm_yes, cad_yes,appet_yes, pe_yes, ane_yes]])\n",
    "print(\"Future_Prediction{}\".format(Future_Prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"finalized_model_Grid.sav\"\n",
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_Grid.sav\",'rb'))\n",
    "result=loaded_model.predict([[36,111,23,34,55,66,44,22,22,11,11,222,111,222,112,1,1,1,0,0,0,0,0,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
